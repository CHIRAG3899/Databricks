{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f50daa85-0435-47aa-a581-32ec0979af2c"}}},{"cell_type":"markdown","source":["# Ingest Data with Auto Loader\n\nDatabricks Auto Loader is the recommended method for streaming raw data from cloud object storage.\n\nFor small datasets, the default **directory listing** execution mode will provide provide exceptional performance and cost savings. As the size of your data scales, the preferred execution method is **file notification**, which requires configuring a connection to your storage queue service and event notification, which will allow Databricks to idempotently track and process all files as they arrive in your storage account.\n\nIn this notebook, we'll go through the basic configuration to ingest the log files for device MAC addresses from partner gyms.\n\n<img src=\"https://files.training.databricks.com/images/ade/ADE_arch_gym_logs.png\" width=\"60%\" />\n\n## Learning Objectives\nBy the end of this lesson, students will be able to:\n- Use Auto Loader to incrementally, indempotently load data from object storage to Delta Tables\n- Locate operation metrics using the `DESCRIBE HISTORY` command"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"550b2b43-1b86-4669-b166-e410bd331ed7"}}},{"cell_type":"markdown","source":["## Setup\n\nThe notebook below defines a function to allow us to manually trigger new data landing in our source container. This will allow us to see Auto Loader in action."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1144f99-a276-441e-ae94-6fe77f8f333f"}}},{"cell_type":"code","source":["%run \"../Includes/gym-mac-log-prep\" $mode=\"reset\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c46e649f-3f42-4b53-9400-1b728fa1a486"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Our source directory contains a number of JSON files representing about a week of data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33014631-b2cb-4229-bfef-ba66ba1af7f2"}}},{"cell_type":"code","source":["files = dbutils.fs.ls(gym_mac_logs)\nfiles"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e090e8e1-f6a3-46b6-8320-df9885bfd95a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's read in a file and grab the schema."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b473dbca-f2c8-4f3e-a0a5-9c2670bb7ae9"}}},{"cell_type":"code","source":["schema = spark.read.json(files[0].path).schema\nschema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb43a0db-20c7-481a-8246-4659d6d607f8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Using CloudFiles\n\nConfiguring Auto Loader requires using the `cloudFiles` format. The syntax for this format differs only slightly from a standard streaming read.\n\nAll we need to ddo is replace our file format with `cloudFiles`, and add the file type as a string for the option `cloudFiles.format`.\n\nAdditional [configuration options](https://docs.databricks.com/spark/latest/structured-streaming/auto-loader.html#configuration) are available."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5d653888-ee33-441f-852d-3279a476084a"}}},{"cell_type":"code","source":["def load_gym_logs():\n    (spark.readStream.format(\"cloudFiles\")\n        .option(\"cloudFiles.format\", \"json\")\n        .schema(schema)\n        .load(gym_mac_logs)\n        .writeStream\n        .format(\"delta\")\n        .option(\"checkpointLocation\", Paths.gymMacLogsCheckpoint)\n        .trigger(once=True)\n        .option(\"path\", Paths.gymMacLogs)\n        .table(\"gym_mac_logs\")\n        .awaitTermination())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18c2788c-6e61-4997-8572-453bf02d7603"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note that we're using trigger once logic for batch execution. While we may not have the latency requirements of a Structured Streaming workload, Auto Loader prevents any CDC on our file source, allowing us to simply trigger a chron job daily to process all new data that's arrived."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"939fc7d4-871d-4d03-9a50-cd572d4b630d"}}},{"cell_type":"code","source":["load_gym_logs()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53818eb0-3562-40b1-b90e-0b6082c3fc2a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["As always, each batch of newly processed data will create a new version of our table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8eeacb85-aa92-4b58-81e8-f69a3a6be1e7"}}},{"cell_type":"code","source":["display(spark.sql(f\"DESCRIBE HISTORY delta.`{Paths.gymMacLogs}`\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a64d3e59-a132-4686-bdc4-676a10b9052c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The helper method below will load an additional day of data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ef58d01-ed56-4594-9b4a-3b3136efae57"}}},{"cell_type":"code","source":["NewFile.arrival()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"018e1ba0-b3a3-462f-95e7-05b775aecde8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Cloud Files will ignore previously processed data; only those newly written files will be processed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d0752ea-7140-4f1b-8f51-4996e3057981"}}},{"cell_type":"code","source":["load_gym_logs()\ndisplay(spark.sql(f\"DESCRIBE HISTORY delta.`{Paths.gymMacLogs}`\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3518c5a4-14bd-4f26-ac79-90ab650ed100"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the cell below to process the remainder of the data provided."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5aca09be-4c4b-45e3-a96f-572c35d895be"}}},{"cell_type":"code","source":["NewFile.arrival(continuous=True)\nload_gym_logs()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20ab1a8b-33af-4d30-9830-95bc87a14085"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now we can use SQL to examine our data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e105fc74-7730-420d-8f36-06a482b8e663"}}},{"cell_type":"code","source":["%sql\nSELECT * FROM gym_mac_logs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c06b9a4-194c-43f6-a9a1-38e5e5cf9be4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2021 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2edf2b0d-35f0-4d2b-80c4-9eae9930d8fc"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ADES 2.01 - Auto Loader","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2598055170583481}},"nbformat":4,"nbformat_minor":0}
