{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbfc5caf-ddfc-45b8-8b21-eb8b8980145a"}}},{"cell_type":"markdown","source":["# Setting Up Tables\nManaging database and table metadata, locations, and configurations at the beginning of project can help to increase data security, discoverability, and performance.\n\n## Learning Objectives\nBy the end of this notebook, students will be able to:\n- Set database locations\n- Specify database comments\n- Set table locations\n- Specify table comments\n- Specify column comments\n- Use table properties for custom tagging\n- Explore table metadata"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b763d813-e880-4132-a4d6-2fa714587055"}}},{"cell_type":"markdown","source":["## Setup Variables\n\nThe following script clears out previous runs of this demo and configures some Hive variables that will be used in our SQL queries."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4e82911-f594-4945-9681-551424815a19"}}},{"cell_type":"code","source":["%run ../Includes/sql-setup $lesson=\"demo\" $mode=\"reset\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0e276c4-506e-4f81-b615-39da6f66250a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Notebook not found: Users/chiraggoel@kpmg.com/Applied-Data-Engineering-Solutions/Includes/_user. Notebooks can be specified via a relative path (./Notebook or ../folder/Notebook) or via an absolute path (/Abs/Path/to/Notebook). Make sure you are specifying the path correctly.\n\nStacktrace:\n  /Users/chiraggoel@kpmg.com/Applied-Data-Engineering-Solutions/01 - Architecting For The Lakehouse/ADES 1.01 - Setting Up Tables: python\n  /Users/chiraggoel@kpmg.com/Applied-Data-Engineering-Solutions/Includes/sql-setup: python","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Using Hive Variables\n\nWhile not a pattern that is generally recommended in Spark SQL, this notebook will use some Hive variables to substitute in string values derived from the account email of the current user.\n\nThe following cell demonstrates this pattern."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fb0ac3c-54fd-4179-ad2d-21b44d5aded3"}}},{"cell_type":"code","source":["%sql\nSELECT \"${c.database}\";"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b65ca67-60c9-4934-baf8-7366dafc55a2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Using this syntax is identical to typing the associated string value into a SQL query.\n\nRun the following to make sure no database with the provided name exists."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e128ddd7-81c3-4f56-bcca-7a2c85567246"}}},{"cell_type":"code","source":["%sql\nDROP DATABASE IF EXISTS ${c.database} CASCADE"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ce80cc9-ae22-4c06-a84a-d445e5e10223"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Creating a Database with Options\n\nThe following cell demonstrates the syntax for creating a database while:\n1. Setting a database comment\n1. Specifying a database location\n1. Adding an arbitrary key-value pair as a database property\n\nAn arbitrary directory on the DBFS root is being used for the location; in any stage of development or production, it is best practice to create databases in secure cloud object storage with credentials locked down to appropriate teams within the organization.\n\n**NOTE**: Remember that by default, all managed tables will be created within the directory declared as the location when a database is created."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8385bee7-e0c4-4e6a-8d56-4b3f6b64a8d0"}}},{"cell_type":"code","source":["%sql\nCREATE DATABASE ${c.database}\nCOMMENT \"This is a test database\"\nLOCATION \"${c.userhome}\"\nWITH DBPROPERTIES (contains_pii = true)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93391e91-45e2-41f0-87d8-0bd2a7e6ae66"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["All of the comments and properties set during database declaration can be reviewed using `DESCRIBE DATABASE EXTENDED`.\n\nThis information can aid in data discovery, auditing, and governance. Having proactive rules about how databases will be created and tagged can help prevent accidental data exfiltration, redundancies, and deletions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"496fac34-0c94-4c73-848f-724379ecc10c"}}},{"cell_type":"code","source":["%sql\nDESCRIBE DATABASE EXTENDED ${c.database}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8d3b2ff-0b66-4199-a78c-bfd9928236d8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Creating a Table with Options\nThe following cell demonstrates creating a **managed** Delta Lake table while:\n1. Setting a column comment\n1. Setting a table comment\n1. Adding an arbitrary key-value pair as a table property\n\n**NOTE**: A number of Delta Lake configurations are also set using `TBLPROPERTIES`. When using this field as part of an organizational approach to data discovery and auditting, users should be made aware of which keys are leveraged for modifying default Delta Lake behaviors."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2d1bcb6-8eb3-4d5a-a9d5-4d7b45eb2ff2"}}},{"cell_type":"code","source":["%sql\nCREATE TABLE ${c.database}.pii_test\n(id INT, name STRING COMMENT \"PII\")\nCOMMENT \"Contains PII\"\nTBLPROPERTIES ('contains_pii' = True) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69b0dcfa-5260-4fb6-8f14-026de18a17db"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Much like the command for reviewing database metadata settings, `DESCRIBE EXTENDED` allows users to see all of the comments and properties for a given table.\n\n**NOTE**: Delta Lake automatically adds several table properties on table creation."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9764ddc2-f60a-4f5c-adf6-3d50084b083c"}}},{"cell_type":"code","source":["%sql\nDESCRIBE EXTENDED ${c.database}.pii_test"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"096f03c6-253f-4c8d-b0d5-ad221278ce9c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Below the code from above is replicated with the addition of specifying a location, creating an **external** table.\n\n**NOTE**: The only thing that differentiates managed and external tables is this location setting. Performance of managed and external tables should be equivalent with regards to latency, but the results of SQL DDL statements on these tables differ drastically."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c028b7b-4593-4a36-8348-fd14ecc0bc53"}}},{"cell_type":"code","source":["%sql\nCREATE TABLE ${c.database}.pii_test_2\n(id INT, name STRING COMMENT \"PII\")\nCOMMENT \"Contains PII\"\nLOCATION \"${c.userhome}/pii_test_2\"\nTBLPROPERTIES ('contains_pii' = True) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"299b4238-b23a-4100-99d0-d4f51dbe7ff4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["As expected, the only differences in the extended description of the table have to do with the table location and type."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4307256-9706-4f30-988e-32af4a53b674"}}},{"cell_type":"code","source":["%sql\nDESCRIBE EXTENDED ${c.database}.pii_test_2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dce1b0c6-7a04-4b7f-9609-25052ca874d7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Using Table Metadata\n\nAssuming that rules are followed appropriately when creating databases and tables, comments, table properties, and other metadata can be interacted with programmatically for discovering datasets for governance and auditing purposes.\n\nThe Python code below demonstrates parsing the table properties field, filtering those options that are specifically geared toward controlling Delta Lake behavior. In this case, logic could be written to further parse these properties to identify all tables in a database that contain PII."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aeafeb28-1b16-452a-bbd8-35fb51d84f73"}}},{"cell_type":"code","source":["def parse_table_keys(database):\n    table_keys = {}\n    for table in spark.sql(f\"SHOW TABLES IN {database}\").collect():\n        table_name = table[1]\n        key_values = spark.sql(f\"DESCRIBE EXTENDED {database}.{table_name}\").filter(\"col_name = 'Table Properties'\").collect()[0][1][1:-1].split(\",\")\n        table_keys[table_name] = [kv for kv in key_values if not kv.startswith(\"delta.\")]\n    return table_keys\n\nparse_table_keys(database)   "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f92d8f4-e641-411c-b69b-7ced82473457"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2021 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09ddcba3-37e9-4097-b7d0-8b445442397f"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ADES 1.01 - Setting Up Tables","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2598055170583302}},"nbformat":4,"nbformat_minor":0}
