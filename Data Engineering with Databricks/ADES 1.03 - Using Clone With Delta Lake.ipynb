{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"134ce990-9282-4170-afda-4fd2775fb519"}}},{"cell_type":"markdown","source":["# Using Clone with Delta Lake\n\nDelta Lake provides native support for copying existing tables with `CLONE`. This notebook will explore both deep and shallow clones. The docs for this feature are [here](https://docs.databricks.com/delta/delta-utility.html#clone-a-delta-table); full syntax docs are available [here](https://docs.databricks.com/spark/latest/spark-sql/language-manual/delta-clone.html).\n\n## Learning Objectives\nBy the end of this lesson, you should be able to:\n* Use deep clones to create full incremental backups of tables\n* Use shallow clones to create development datasets\n* Describe expected behavior after performing common database operations on source and clone tables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a94cefb-aa73-454f-b9b1-bd4aee9d2955"}}},{"cell_type":"markdown","source":["## Configure the environment\nThe following cell will create a database and source table that we'll use in this lesson, alongside some variables we'll use to control file locations."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e70b179c-3b46-4e8c-af3c-723326f3628c"}}},{"cell_type":"code","source":["%run ../Includes/clone-setup $mode=\"reset\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4836ac4f-9276-4f03-8aa1-a26081953512"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Notebook not found: Users/chiraggoel@kpmg.com/Applied-Data-Engineering-Solutions/Includes/_user. Notebooks can be specified via a relative path (./Notebook or ../folder/Notebook) or via an absolute path (/Abs/Path/to/Notebook). Make sure you are specifying the path correctly.\n\nStacktrace:\n  /Users/chiraggoel@kpmg.com/Applied-Data-Engineering-Solutions/01 - Architecting For The Lakehouse/ADES 1.03 - Using Clone With Delta Lake: python\n  /Users/chiraggoel@kpmg.com/Applied-Data-Engineering-Solutions/Includes/clone-setup: python","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Look at the production table details\nThe production table we'll be using as our source is named `sensors_prod`.\n\nUse the following cell to explore the table history. Note that 4 total transactions have been run to create and load data into this table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e4a71ba-ea6a-4492-bdf6-af8314aeaad9"}}},{"cell_type":"code","source":["%sql\nDESCRIBE HISTORY sensors_prod"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d174636-400f-4037-a277-b59cde172c11"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Explore the table description to discover the schema and additional details. Note that comments have been added to describe each data field."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72ee9051-378c-48c9-a806-eea5b7c26fff"}}},{"cell_type":"code","source":["%sql\nDESCRIBE FORMATTED sensors_prod"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"587bd11f-fb35-40bb-ad17-8e16168ac3b3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The helper function `check_files` was defined to accept a table name and return the count of underlying data files (as well as list the content of the table directory).\n\nRecall that all Delta tables comprise:\n1. Data files stored in parquet format\n1. Transaction logs stored in the `_delta_log` directory\n\nThe table name we're interacting with in the metastore is just a pointer to these underlying assets."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"328dfbdf-188f-4235-8471-ec2d69ff3557"}}},{"cell_type":"code","source":["check_files(\"sensors_prod\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a471271-0b92-496d-81f7-bb16fb2a1c71"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Create a backup of your dataset with deep clone\n\nDeep clone will copy all data and metadata files from your source table to a specified location, registering it with the declared table name."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0bd1043d-1e0d-4ade-b26d-817a18f57249"}}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TABLE sensors_backup \nDEEP CLONE sensors_prod\nLOCATION '${c.userhome}/backup/sensors'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b302d425-f083-400f-a302-ac5e032c7f55"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["You'll recall that our `sensors_prod` table had 4 versions associated with it. The clone operation created version 0 of the cloned table. \n\nThe `operationsParameters` field indicates the `sourceVersion` that was cloned.\n\nThe `operationMetrics` field will provide information about the files copied during this transaction."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"651714da-768a-46dd-a788-c67c83616f84"}}},{"cell_type":"code","source":["%sql\nDESCRIBE HISTORY sensors_backup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8cc6e7c-0d20-4dec-95c3-22dbb338385f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Metadata like comments will also be cloned."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f2c7398-e601-4a10-a5bd-f9cfe3fde4be"}}},{"cell_type":"code","source":["%sql\nDESCRIBE FORMATTED sensors_backup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9454c0ba-532f-4553-b27d-a125db575271"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Incremental Cloning\n\nIf you examine the files in your backup table, you'll see that you have the same number of files as your source table. Upon closer examination, you'll note that file names and sizes have also been preserved by the clone. \n\nThis allows Delta Lake to incrementally apply changes to the backup table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14768e62-ae3b-4a61-b696-46c08c396280"}}},{"cell_type":"code","source":["check_files(\"sensors_backup\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84066181-d825-437c-98a0-f998437ad17d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["To see incremental clone in action, begin by commiting a transaction to the `sensor_prod` table. Here, we'll delete all those records where `sensor_type` is `C`.\n\nRemember that Delta Lake manages changes at the file level, so any file containing a matching record will be rewritten."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4590fbd-f6da-44a6-9269-34353623b300"}}},{"cell_type":"code","source":["%sql\nDELETE FROM sensors_prod WHERE sensor_type = 'C'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff8a45fd-c416-4590-895c-8d56183d36c2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["When we re-execute our deep clone command, we only copy those files that were written during our most recent transaction."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37a4865b-0c91-4a8b-86c7-24df52e75271"}}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TABLE sensors_backup \nDEEP CLONE sensors_prod\nLOCATION '${c.userhome}/backup/sensors'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed5ebf7e-85ad-4917-9c16-55ce5a30e980"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can review our history to confirm this."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b33586ec-d51c-4073-a940-9533ae52afa3"}}},{"cell_type":"code","source":["%sql\nDESCRIBE HISTORY sensors_backup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2033de0f-6c42-4b79-9f70-74e52222d6ed"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Creating Development Datasets with Shallow Clone\n\nWhereas deep clone copies both data and metadata, shallow clone just copies the metadata and creates a pointer to the existing data files.\n\nNote that the cloned table will have read-only permissions on the source data files. This makes it easy to create development datasets using a production dataset without fear of table corruption.\n\nHere, we'll also specify using version 2 of our source production table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b55b71a-069e-4dad-a8ad-0fe5ea6d2a7e"}}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TABLE sensors_dev\nSHALLOW CLONE sensors_prod@v2\nLOCATION '${c.userhome}/dev/sensors'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1876bedd-f19d-4661-9604-11eda916d5bb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["When we look at the target directory, we'll note that no data files exist. The metadata for this table just points to those data files in the source table's data directory."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9111a5c-7761-4a93-8ca2-dbf580b65c8a"}}},{"cell_type":"code","source":["check_files(\"sensors_dev\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"326ec186-ceae-4528-9c76-95c7307d202d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Apply Changes to Dev Data\nBut what happens if you want to test modifications to your dev table?\n\nThe code below inserts only those records from version 3 of our production table that don't have the value \"C\" as a `sensor_type`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"391c6812-e7c7-4ee1-9b7e-819dcd9fa575"}}},{"cell_type":"code","source":["%sql\nMERGE INTO sensors_dev dev\nUSING (SELECT * FROM sensors_prod@v3 WHERE sensor_type != \"C\") prod\nON dev.device_id = prod.device_id AND dev.time = prod.time\nWHEN NOT MATCHED THEN INSERT *"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f054286-420d-48af-9b23-a5757178619e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The operation is successful and new rows are inserted. If we check the contents of our table location, we'll see that data files now exists."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5af375a8-9cba-482f-b573-a3dc04f98c3b"}}},{"cell_type":"code","source":["check_files(\"sensors_dev\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d205c42e-23ad-4e28-b940-0e7759c2aa46"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Any changes made to a shallow cloned table will write new data files to the specified target directory, meaning that you can safely test writes, updates, and deletes without risking corruption of your original table. The Delta logs will automatically reference the correct files (from the source table and this clone directory) to materialize the current view of your dev table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66ea1921-521e-4db5-83de-003aeee1d537"}}},{"cell_type":"markdown","source":["## File Retention and Cloned Tables\n\nIt's important to understand how cloned tables behave with file retention actions.\n\nRun the cell below to `VACUUM` your source production table (removing all files not referenced in the most recent version)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e9850eb-da14-4d63-bf02-c808cfa06c38"}}},{"cell_type":"code","source":["spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", False)\nspark.sql(\"VACUUM sensors_prod RETAIN 0 HOURS\")\nspark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c668880-1951-4806-81af-cbbcb6315cc1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We see that there are now fewer total data files associated with this table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c776cb9f-9116-4157-9477-30f48b159770"}}},{"cell_type":"code","source":["check_files(\"sensors_prod\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a86dc37d-d3ac-45cc-b87e-8a1518dbd2aa"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["You'll recall that our `sensors_dev` table was initialized against version 2 of our production table. As such, it still has reference to data files associated with that table version.\n\nBecause these data files have been removed by our vacuum operation, we should expect the following query against our shallow cloned table to fail."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed536e34-2665-4ab2-834b-a9de7c59da6a"}}},{"cell_type":"code","source":["%sql\nSELECT * FROM sensors_dev"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c98ddd35-d6d5-47db-aa07-53d2bcd0e7c0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Because deep clone created a full copy of our files and associated metadata, we still have access to our `sensors_backup` table. Here, we'll query the original version of this backup (which corresponds to version 3 of our source table)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"760ed616-b898-49e1-89dd-6e6e14a26f6e"}}},{"cell_type":"code","source":["%sql\nSELECT * FROM sensors_backup@v0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"267d852f-9639-49ec-ab13-ec4d70f99a40"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["One of the useful features of deep cloning is the ability to set different table properties for file and log retention. This allows production tables to have optimized performance while maintaining files for auditing and regulatory compliance. \n\nThe cell below sets the log and deleted file retention periods to 10 years."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e48458cd-49d2-49c4-900b-7e7371a90fff"}}},{"cell_type":"code","source":["%sql\nALTER TABLE sensors_backup\nSET TBLPROPERTIES (\n  delta.logRetentionDuration = '3650 days',\n  delta.deletedFileRetentionDuration = '3650 days'\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"838768ed-6432-4774-9816-8a2b2a20662b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Wrapping Up\n\nIn this notebook, we explored the basic syntax and behavior of deep and shallow clones. We saw how changes to source and clone tables impacted tables, including the ability to incrementally clone changes to keep a backup table in-sync with its source. We saw that shallow clone could be used for creating temporary tables for development based on production data, but noted that removal of source data files will lead to errors when trying to query this shallow clone.\n\nRun the following cell to delete the tables and files associated with this demo."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be37bc31-043b-45f2-86c7-07b8d24e60d4"}}},{"cell_type":"code","source":["%run ../Includes/clone-setup $mode=\"cleanup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e41a167-9091-4c85-aa63-073307388421"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2021 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a693e35b-a615-47cc-929e-16bd5bed08d1"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ADES 1.03 - Using Clone With Delta Lake","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2598055170583224}},"nbformat":4,"nbformat_minor":0}
