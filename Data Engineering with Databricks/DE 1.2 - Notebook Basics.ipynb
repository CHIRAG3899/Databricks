{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b99ff305-aa05-4936-a2a3-74ca272b04dd"}}},{"cell_type":"markdown","source":["# Notebook Basics\n\nNotebooks are the primary means of developing and executing code interactively on Databricks. This lesson provides a basic introduction to working with Databricks notebooks.\n\nIf you've previously used Databricks notebooks but this is your first time executing a notebook in Databricks Repos, you'll notice that basic functionality is the same. In the next lesson, we'll review some of the functionality that Databricks Repos adds to notebooks.\n\n## Learning Objectives\nBy the end of this lesson, you should be able to:\n* Attach a notebook to a cluster\n* Execute a cell in a notebook\n* Set the language for a notebook\n* Describe and use magic commands\n* Create and run a SQL cell\n* Create and run a Python cell\n* Create a markdown cell\n* Export a Databricks notebook\n* Export a collection of Databricks notebooks"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b39d1dd-84d3-4745-bcb4-d37338b29584"}}},{"cell_type":"markdown","source":["## Attach to a Cluster\n\nIn the previous lesson, you should have either deployed a cluster or identified a cluster that an admin has configured for you to use.\n\nDirectly below the name of this notebook at the top of your screen, use the drop-down list to connect this notebook to your cluster.\n\n**NOTE**: Deploying a cluster can take several minutes. A green arrow will appear to the right of the cluster name once resources have been deployed. If your cluster has a solid gray circle to the left, you will need to follow instructions to <a href=\"https://docs.databricks.com/clusters/clusters-manage.html#start-a-cluster\" target=\"_blank\">start a cluster</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"300dd734-5c78-48a6-b209-6a5d802ec760"}}},{"cell_type":"markdown","source":["## Notebooks Basics\n\nNotebooks provide cell-by-cell execution of code. Multiple languages can be mixed in a notebook. Users can add plots, images, and markdown text to enhance their code.\n\nThroughout this course, our notebooks are designed as learning instruments. Notebooks can be easily deployed as production code with Databricks, as well as providing a robust toolset for data exploration, reporting, and dashboarding.\n\n### Running a Cell\n* Run the cell below using one of the following options:\n  * **CTRL+ENTER** or **CTRL+RETURN**\n  * **SHIFT+ENTER** or **SHIFT+RETURN** to run the cell and move to the next one\n  * Using **Run Cell**, **Run All Above** or **Run All Below** as seen here<br/><img style=\"box-shadow: 5px 5px 5px 0px rgba(0,0,0,0.25); border: 1px solid rgba(0,0,0,0.25);\" src=\"https://files.training.databricks.com/images/notebook-cell-run-cmd.png\"/>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5393c3d-aa1e-49d3-9b4e-f63f62fc154e"}}},{"cell_type":"code","source":["print(\"I'm running Python!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78221383-2ba0-4e17-a654-bc58a1a3fe1c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"I'm running Python!\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["I'm running Python!\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**NOTE**: Cell-by-cell code execution means that cells can be executed multiple times or out of order. Unless explicitly instructed, you should always assume that the notebooks in this course are intended to be run one cell at a time from top to bottom. If you encounter an error, make sure you read the text before and after a cell to ensure that the error wasn't an intentional learning moment before you try to troubleshoot. Most errors can be resolved by either running earlier cells in a notebook that were missed or re-executing the entire notebook from the top."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7c7d0bd-7119-4ad3-a235-7bc293b1d75c"}}},{"cell_type":"markdown","source":["### Setting the Default Notebook Language\n\nThe cell above executes a Python command, because our current default language for the notebook is set to Python.\n\nDatabricks notebooks support Python, SQL, Scala, and R. A language can be selected when a notebook is created, but this can be changed at any time.\n\nThe default language appears directly to the right of the notebook title at the top of the page. Throughout this course, we'll use a blend of SQL and Python notebooks.\n\nWe'll change the default language for this notebook to SQL.\n\nSteps:\n* Click on the **Python** next to the notebook title at the top of the screen\n* In the UI that pops up, select **SQL** from the drop down list \n\n**NOTE**: In the cell just before this one, you should see a new line appear with <strong><code>&#37;python</code></strong>. We'll discuss this in a moment."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf3381be-195a-444a-972f-17a08eb1d070"}}},{"cell_type":"markdown","source":["### Create and Run a SQL Cell\n\n* Highlight this cell and press the **B** button on the keyboard to create a new cell below\n* Copy the following code into the cell below and then run the cell\n\n**`%sql`**<br/>\n**`SELECT \"I'm running SQL!\"`**\n\n**NOTE**: There are a number of different methods for adding, moving, and deleting cells including GUI options and keyboard shortcuts. Refer to the <a href=\"https://docs.databricks.com/notebooks/notebooks-use.html#develop-notebooks\" target=\"_blank\">docs</a> for details."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26eeb347-1345-4c1b-b87f-c76fc450becd"}}},{"cell_type":"markdown","source":["## Magic Commands\n* Magic commands are specific to the Databricks notebooks\n* They are very similar to magic commands found in comparable notebook products\n* These are built-in commands that provide the same outcome regardless of the notebook's language\n* A single percent (%) symbol at the start of a cell identifies a magic command\n  * You can only have one magic command per cell\n  * A magic command must be the first thing in a cell"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80028c45-1cb0-4c1c-b15e-51607b437efb"}}},{"cell_type":"markdown","source":["### Language Magics\nLanguage magic commands allow for the execution of code in languages other than the notebook's default. In this course, we'll see the following language magics:\n* <strong><code>&#37;python</code></strong>\n* <strong><code>&#37;sql</code></strong>\n\nAdding the language magic for the currently set notebook type is not necessary.\n\nWhen we changed the notebook language from Python to SQL above, existing cells written in Python had the <strong><code>&#37;python</code></strong> command added.\n\n**NOTE**: Rather than changing the default language of a notebook constantly, you should stick with a primary language as the default and only use language magics as necessary to execute code in another language."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e9f393f-ba79-4209-88ee-40ec22c28bcf"}}},{"cell_type":"code","source":["print(\"Hello Python!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"931c1332-0a23-4e5c-8b66-2bd10dc4b944"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Hello Python!\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Hello Python!\n"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\nselect \"Hello SQL!\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83a0e7ec-e72c-45c0-93ff-6bea8b9426e9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Hello SQL!"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Hello SQL!","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Hello SQL!</th></tr></thead><tbody><tr><td>Hello SQL!</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Markdown\n\nThe magic command **&percnt;md** allows us to render Markdown in a cell:\n* Double click this cell to begin editing it\n* Then hit **`Esc`** to stop editing\n\n# Title One\n## Title Two\n### Title Three\n\nThis is a test of the emergency broadcast system. This is only a test.\n\nThis is text with a **bold** word in it.\n\nThis is text with an *italicized* word in it.\n\nThis is an ordered list\n0. once\n0. two\n0. three\n\nThis is an unordered list\n* apples\n* peaches\n* bananas\n\nLinks/Embedded HTML: <a href=\"https://en.wikipedia.org/wiki/Markdown\" target=\"_blank\">Markdown - Wikipedia</a>\n\nImages:\n![Spark Engines](https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png)\n\nAnd of course, tables:\n\n| name   | value |\n|--------|-------|\n| Yi     | 1     |\n| Ali    | 2     |\n| Selina | 3     |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c46edef-4596-4131-a38a-2da53ca9e9b6"}}},{"cell_type":"markdown","source":["### %run\n* You can run a notebook from another notebook by using the magic command **%run**\n* Notebooks to be run are specified with relative paths\n* The referenced notebook executes as if it were part of the current notebook, so temporary views and other local declarations will be available from the calling notebook"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f73100a9-e5e7-4fa0-a930-50771209cd0b"}}},{"cell_type":"markdown","source":["Uncommenting and executing the following cell will generate the following error:<br/>\n**`Error in SQL statement: AnalysisException: Table or view not found: demo_tmp_vw`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1784fd22-0d74-47d0-bfe1-2f18f40500ac"}}},{"cell_type":"code","source":["%sql\nSELECT * FROM demo_tmp_vw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd362fa5-e8a9-46da-bc3c-978e1a98e34d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: Table or view not found: demo_tmp_vw; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [demo_tmp_vw], [], false\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$2(CheckAnalysis.scala:137)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$2$adapted(CheckAnalysis.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:358)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:357)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:357)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:357)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:104)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:99)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:99)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:222)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:276)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:331)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:273)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:128)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:151)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:265)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:958)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:265)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:129)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:126)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:118)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:958)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:101)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:793)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:958)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:788)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.$anonfun$executeSql$1(SQLDriverLocal.scala:91)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:37)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:605)\n\tat com.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:28)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\n\tat com.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:26)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:205)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:204)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:60)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:240)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:225)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:60)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:582)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:615)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:607)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:526)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:561)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:431)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:374)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:225)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:130)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:605)\n\tat com.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:28)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\n\tat com.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:26)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:205)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:204)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:60)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:240)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:225)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:60)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:582)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:615)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:607)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:526)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:561)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:431)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:374)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:225)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorSummary":"Error in SQL statement: AnalysisException: Table or view not found: demo_tmp_vw; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [demo_tmp_vw], [], false\n","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\ncom.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: Table or view not found: demo_tmp_vw; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [demo_tmp_vw], [], false\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$2(CheckAnalysis.scala:137)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$2$adapted(CheckAnalysis.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:358)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:357)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:357)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:357)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:104)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:99)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:99)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:222)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:276)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:331)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:273)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:128)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:151)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:265)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:958)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:265)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:129)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:126)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:118)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:958)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:101)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:793)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:958)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:788)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.$anonfun$executeSql$1(SQLDriverLocal.scala:91)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:37)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:605)\n\tat com.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:28)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\n\tat com.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:26)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:205)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:204)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:60)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:240)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:225)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:60)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:582)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:615)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:607)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:526)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:561)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:431)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:374)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:225)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:130)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:145)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$11(DriverLocal.scala:605)\n\tat com.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:28)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\n\tat com.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:26)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:205)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:204)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:60)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:240)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:225)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:60)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:582)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:615)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:607)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:526)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:561)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:431)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:374)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:225)\n\tat java.lang.Thread.run(Thread.java:748)"]}}],"execution_count":0},{"cell_type":"markdown","source":["But we can declare it and a handful of other variables and functions buy running this cell:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f824ad17-d20f-4a3a-970a-057c733e5911"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup-1.2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"562bf5ba-74ba-4821-bc23-16b38dcf47b8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Python interpreter will be restarted.\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nPython interpreter will be restarted.\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Creating the temp view demo_tmp_vw\n\nPredefined Paths:\n  DA.paths.working_dir: dbfs:/user/chiraggoel@kpmg.com/dbacademy/dewd/1.2\n  DA.paths.user_db:     dbfs:/user/chiraggoel@kpmg.com/dbacademy/dewd/1.2/1_2.db\n\nSetup completed in 0 seconds\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Creating the temp view demo_tmp_vw\n\nPredefined Paths:\n  DA.paths.working_dir: dbfs:/user/chiraggoel@kpmg.com/dbacademy/dewd/1.2\n  DA.paths.user_db:     dbfs:/user/chiraggoel@kpmg.com/dbacademy/dewd/1.2/1_2.db\n\nSetup completed in 0 seconds\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["The **`../Includes/Classroom-Setup-1.2`** notebook we referenced includes logic to create and **`USE`** a database, as well as creating the temp view **`demo_temp_vw`**.\n\nWe can see this temp view is now available in our current notebook session with the following query."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5431c78e-8612-456d-8a0e-0ba662abd406"}}},{"cell_type":"code","source":["%sql \nSELECT * FROM demo_tmp_vw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a91a81de-2b74-462c-a7f0-fb09148eb69d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Yi",1],["Ali",2],["Selina",3]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"value","type":"\"integer\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>value</th></tr></thead><tbody><tr><td>Yi</td><td>1</td></tr><tr><td>Ali</td><td>2</td></tr><tr><td>Selina</td><td>3</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We'll use this pattern of \"setup\" notebooks throughout the course to help configure the environment for lessons and labs.\n\nThese \"provided\" variables, functions and other objects should be easily identifiable in that they are part of the **`DA`** object which is an instance of **`DBAcademyHelper`**.\n\nWith that in mind, most lessons will use variables derived from your username to organize files and databases. \n\nThis pattern allows us to avoid collision with other users in shared a workspace.\n\nThe cell below uses Python to print some of those variables previously defined in this notebook's setup script:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c09331f-3ea3-4f1f-b4e1-9c9d8025760f"}}},{"cell_type":"code","source":["print(f\"DA:                   {DA}\")\nprint(f\"DA.username:          {DA.username}\")\nprint(f\"DA.paths.working_dir: {DA.paths.working_dir}\")\nprint(f\"DA.db_name:           {DA.db_name}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7a74458-537a-4527-821c-5a120b9d9cec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"DA:                   <__main__.DBAcademyHelper object at 0x7f43f9bf7b80>\nDA.username:          chiraggoel@kpmg.com\nDA.paths.working_dir: dbfs:/user/chiraggoel@kpmg.com/dbacademy/dewd/1.2\nDA.db_name:           dbacademy_chiraggoel_kpmg_com_dewd_1_2\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["DA:                   <__main__.DBAcademyHelper object at 0x7f43f9bf7b80>\nDA.username:          chiraggoel@kpmg.com\nDA.paths.working_dir: dbfs:/user/chiraggoel@kpmg.com/dbacademy/dewd/1.2\nDA.db_name:           dbacademy_chiraggoel_kpmg_com_dewd_1_2\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["In addition to this, these same variables are \"injected\" into the SQL context so that we can use them in SQL statements.\n\nWe will talk more about this later, but you can see a quick example in the following cell.\n\n<img src=\"https://files.training.databricks.com/images/icon_note_32.png\"> Note the subtle but important difference in the casing of the word **`da`** and **`DA`** in these two examples."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05988f0a-05dc-47c5-8aef-fa17213cbee7"}}},{"cell_type":"code","source":["%sql\nSELECT '${da.username}' AS current_username,\n       '${da.paths.working_dir}' AS working_directory,\n       '${da.db_name}' as database_name"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1d1ba1c-72b5-4e47-9b08-e288d13df962"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["chiraggoel@kpmg.com","dbfs:/user/chiraggoel@kpmg.com/dbacademy/dewd/1.2","dbacademy_chiraggoel_kpmg_com_dewd_1_2"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"current_username","type":"\"string\"","metadata":"{}"},{"name":"working_directory","type":"\"string\"","metadata":"{}"},{"name":"database_name","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>current_username</th><th>working_directory</th><th>database_name</th></tr></thead><tbody><tr><td>chiraggoel@kpmg.com</td><td>dbfs:/user/chiraggoel@kpmg.com/dbacademy/dewd/1.2</td><td>dbacademy_chiraggoel_kpmg_com_dewd_1_2</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Databricks Utilities\nDatabricks notebooks provide a number of utility commands for configuring and interacting with the environment: <a href=\"https://docs.databricks.com/user-guide/dev-tools/dbutils.html\" target=\"_blank\">dbutils docs</a>\n\nThroughout this course, we'll occasionally use **`dbutils.fs.ls()`** to list out directories of files from Python cells."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59f163dc-d2d2-402d-aa07-3280fe669375"}}},{"cell_type":"code","source":["dbutils.fs.ls(\"/databricks-datasets\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4410ee1-5241-479c-b783-6a87809809a5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[12]: [FileInfo(path='dbfs:/databricks-datasets/', name='databricks-datasets/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/COVID/', name='COVID/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/README.md', name='README.md', size=976, modificationTime=1532468253000),\n FileInfo(path='dbfs:/databricks-datasets/Rdatasets/', name='Rdatasets/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/SPARK_README.md', name='SPARK_README.md', size=3359, modificationTime=1455043490000),\n FileInfo(path='dbfs:/databricks-datasets/adult/', name='adult/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/airlines/', name='airlines/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/amazon/', name='amazon/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/asa/', name='asa/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/atlas_higgs/', name='atlas_higgs/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/bikeSharing/', name='bikeSharing/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/cctvVideos/', name='cctvVideos/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/credit-card-fraud/', name='credit-card-fraud/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/cs100/', name='cs100/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/cs110x/', name='cs110x/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/cs190/', name='cs190/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/data.gov/', name='data.gov/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/definitive-guide/', name='definitive-guide/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/delta-sharing/', name='delta-sharing/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/flights/', name='flights/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/flower_photos/', name='flower_photos/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/flowers/', name='flowers/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/genomics/', name='genomics/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/hail/', name='hail/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/identifying-campaign-effectiveness/', name='identifying-campaign-effectiveness/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/iot/', name='iot/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/iot-stream/', name='iot-stream/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/learning-spark/', name='learning-spark/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/learning-spark-v2/', name='learning-spark-v2/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/lending-club-loan-stats/', name='lending-club-loan-stats/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/med-images/', name='med-images/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/media/', name='media/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/mnist-digits/', name='mnist-digits/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/news20.binary/', name='news20.binary/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/nyctaxi/', name='nyctaxi/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/nyctaxi-with-zipcodes/', name='nyctaxi-with-zipcodes/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/online_retail/', name='online_retail/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/overlap-join/', name='overlap-join/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/power-plant/', name='power-plant/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/retail-org/', name='retail-org/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/rwe/', name='rwe/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/sai-summit-2019-sf/', name='sai-summit-2019-sf/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/sample_logs/', name='sample_logs/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/samples/', name='samples/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/sfo_customer_survey/', name='sfo_customer_survey/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/sms_spam_collection/', name='sms_spam_collection/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/songs/', name='songs/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/structured-streaming/', name='structured-streaming/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/timeseries/', name='timeseries/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/tpch/', name='tpch/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/warmup/', name='warmup/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/weather/', name='weather/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/wiki/', name='wiki/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/wikipedia-datasets/', name='wikipedia-datasets/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/wine-quality/', name='wine-quality/', size=0, modificationTime=0)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[12]: [FileInfo(path='dbfs:/databricks-datasets/', name='databricks-datasets/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/COVID/', name='COVID/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/README.md', name='README.md', size=976, modificationTime=1532468253000),\n FileInfo(path='dbfs:/databricks-datasets/Rdatasets/', name='Rdatasets/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/SPARK_README.md', name='SPARK_README.md', size=3359, modificationTime=1455043490000),\n FileInfo(path='dbfs:/databricks-datasets/adult/', name='adult/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/airlines/', name='airlines/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/amazon/', name='amazon/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/asa/', name='asa/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/atlas_higgs/', name='atlas_higgs/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/bikeSharing/', name='bikeSharing/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/cctvVideos/', name='cctvVideos/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/credit-card-fraud/', name='credit-card-fraud/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/cs100/', name='cs100/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/cs110x/', name='cs110x/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/cs190/', name='cs190/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/data.gov/', name='data.gov/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/definitive-guide/', name='definitive-guide/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/delta-sharing/', name='delta-sharing/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/flights/', name='flights/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/flower_photos/', name='flower_photos/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/flowers/', name='flowers/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/genomics/', name='genomics/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/hail/', name='hail/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/identifying-campaign-effectiveness/', name='identifying-campaign-effectiveness/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/iot/', name='iot/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/iot-stream/', name='iot-stream/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/learning-spark/', name='learning-spark/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/learning-spark-v2/', name='learning-spark-v2/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/lending-club-loan-stats/', name='lending-club-loan-stats/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/med-images/', name='med-images/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/media/', name='media/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/mnist-digits/', name='mnist-digits/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/news20.binary/', name='news20.binary/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/nyctaxi/', name='nyctaxi/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/nyctaxi-with-zipcodes/', name='nyctaxi-with-zipcodes/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/online_retail/', name='online_retail/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/overlap-join/', name='overlap-join/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/power-plant/', name='power-plant/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/retail-org/', name='retail-org/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/rwe/', name='rwe/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/sai-summit-2019-sf/', name='sai-summit-2019-sf/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/sample_logs/', name='sample_logs/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/samples/', name='samples/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/sfo_customer_survey/', name='sfo_customer_survey/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/sms_spam_collection/', name='sms_spam_collection/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/songs/', name='songs/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/structured-streaming/', name='structured-streaming/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/timeseries/', name='timeseries/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/tpch/', name='tpch/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/warmup/', name='warmup/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/weather/', name='weather/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/wiki/', name='wiki/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/wikipedia-datasets/', name='wikipedia-datasets/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/databricks-datasets/wine-quality/', name='wine-quality/', size=0, modificationTime=0)]"]}}],"execution_count":0},{"cell_type":"markdown","source":["## display()\n\nWhen running SQL queries from cells, results will always be displayed in a rendered tabular format.\n\nWhen we have tabular data returned by a Python cell, we can call **`display`** to get the same type of preview.\n\nHere, we'll wrap the previous list command on our file system with **`display`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a602da2-f32c-407a-952f-bf6d178920d2"}}},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/databricks-datasets\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f93c39ad-e252-46d3-b1d8-ae89f045a94d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/databricks-datasets/","databricks-datasets/",0,0],["dbfs:/databricks-datasets/COVID/","COVID/",0,0],["dbfs:/databricks-datasets/README.md","README.md",976,1532468253000],["dbfs:/databricks-datasets/Rdatasets/","Rdatasets/",0,0],["dbfs:/databricks-datasets/SPARK_README.md","SPARK_README.md",3359,1455043490000],["dbfs:/databricks-datasets/adult/","adult/",0,0],["dbfs:/databricks-datasets/airlines/","airlines/",0,0],["dbfs:/databricks-datasets/amazon/","amazon/",0,0],["dbfs:/databricks-datasets/asa/","asa/",0,0],["dbfs:/databricks-datasets/atlas_higgs/","atlas_higgs/",0,0],["dbfs:/databricks-datasets/bikeSharing/","bikeSharing/",0,0],["dbfs:/databricks-datasets/cctvVideos/","cctvVideos/",0,0],["dbfs:/databricks-datasets/credit-card-fraud/","credit-card-fraud/",0,0],["dbfs:/databricks-datasets/cs100/","cs100/",0,0],["dbfs:/databricks-datasets/cs110x/","cs110x/",0,0],["dbfs:/databricks-datasets/cs190/","cs190/",0,0],["dbfs:/databricks-datasets/data.gov/","data.gov/",0,0],["dbfs:/databricks-datasets/definitive-guide/","definitive-guide/",0,0],["dbfs:/databricks-datasets/delta-sharing/","delta-sharing/",0,0],["dbfs:/databricks-datasets/flights/","flights/",0,0],["dbfs:/databricks-datasets/flower_photos/","flower_photos/",0,0],["dbfs:/databricks-datasets/flowers/","flowers/",0,0],["dbfs:/databricks-datasets/genomics/","genomics/",0,0],["dbfs:/databricks-datasets/hail/","hail/",0,0],["dbfs:/databricks-datasets/identifying-campaign-effectiveness/","identifying-campaign-effectiveness/",0,0],["dbfs:/databricks-datasets/iot/","iot/",0,0],["dbfs:/databricks-datasets/iot-stream/","iot-stream/",0,0],["dbfs:/databricks-datasets/learning-spark/","learning-spark/",0,0],["dbfs:/databricks-datasets/learning-spark-v2/","learning-spark-v2/",0,0],["dbfs:/databricks-datasets/lending-club-loan-stats/","lending-club-loan-stats/",0,0],["dbfs:/databricks-datasets/med-images/","med-images/",0,0],["dbfs:/databricks-datasets/media/","media/",0,0],["dbfs:/databricks-datasets/mnist-digits/","mnist-digits/",0,0],["dbfs:/databricks-datasets/news20.binary/","news20.binary/",0,0],["dbfs:/databricks-datasets/nyctaxi/","nyctaxi/",0,0],["dbfs:/databricks-datasets/nyctaxi-with-zipcodes/","nyctaxi-with-zipcodes/",0,0],["dbfs:/databricks-datasets/online_retail/","online_retail/",0,0],["dbfs:/databricks-datasets/overlap-join/","overlap-join/",0,0],["dbfs:/databricks-datasets/power-plant/","power-plant/",0,0],["dbfs:/databricks-datasets/retail-org/","retail-org/",0,0],["dbfs:/databricks-datasets/rwe/","rwe/",0,0],["dbfs:/databricks-datasets/sai-summit-2019-sf/","sai-summit-2019-sf/",0,0],["dbfs:/databricks-datasets/sample_logs/","sample_logs/",0,0],["dbfs:/databricks-datasets/samples/","samples/",0,0],["dbfs:/databricks-datasets/sfo_customer_survey/","sfo_customer_survey/",0,0],["dbfs:/databricks-datasets/sms_spam_collection/","sms_spam_collection/",0,0],["dbfs:/databricks-datasets/songs/","songs/",0,0],["dbfs:/databricks-datasets/structured-streaming/","structured-streaming/",0,0],["dbfs:/databricks-datasets/timeseries/","timeseries/",0,0],["dbfs:/databricks-datasets/tpch/","tpch/",0,0],["dbfs:/databricks-datasets/warmup/","warmup/",0,0],["dbfs:/databricks-datasets/weather/","weather/",0,0],["dbfs:/databricks-datasets/wiki/","wiki/",0,0],["dbfs:/databricks-datasets/wikipedia-datasets/","wikipedia-datasets/",0,0],["dbfs:/databricks-datasets/wine-quality/","wine-quality/",0,0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"},{"name":"modificationTime","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/</td><td>databricks-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/COVID/</td><td>COVID/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/README.md</td><td>README.md</td><td>976</td><td>1532468253000</td></tr><tr><td>dbfs:/databricks-datasets/Rdatasets/</td><td>Rdatasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/SPARK_README.md</td><td>SPARK_README.md</td><td>3359</td><td>1455043490000</td></tr><tr><td>dbfs:/databricks-datasets/adult/</td><td>adult/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/airlines/</td><td>airlines/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/amazon/</td><td>amazon/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/asa/</td><td>asa/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/atlas_higgs/</td><td>atlas_higgs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/bikeSharing/</td><td>bikeSharing/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cctvVideos/</td><td>cctvVideos/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/credit-card-fraud/</td><td>credit-card-fraud/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs100/</td><td>cs100/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs110x/</td><td>cs110x/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs190/</td><td>cs190/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/data.gov/</td><td>data.gov/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/definitive-guide/</td><td>definitive-guide/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/delta-sharing/</td><td>delta-sharing/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flights/</td><td>flights/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flower_photos/</td><td>flower_photos/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flowers/</td><td>flowers/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/genomics/</td><td>genomics/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/hail/</td><td>hail/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/identifying-campaign-effectiveness/</td><td>identifying-campaign-effectiveness/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/iot/</td><td>iot/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/iot-stream/</td><td>iot-stream/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark/</td><td>learning-spark/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/</td><td>learning-spark-v2/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/lending-club-loan-stats/</td><td>lending-club-loan-stats/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/med-images/</td><td>med-images/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/media/</td><td>media/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/mnist-digits/</td><td>mnist-digits/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/news20.binary/</td><td>news20.binary/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/nyctaxi/</td><td>nyctaxi/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/nyctaxi-with-zipcodes/</td><td>nyctaxi-with-zipcodes/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/online_retail/</td><td>online_retail/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/overlap-join/</td><td>overlap-join/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/power-plant/</td><td>power-plant/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/retail-org/</td><td>retail-org/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/rwe/</td><td>rwe/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sai-summit-2019-sf/</td><td>sai-summit-2019-sf/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sample_logs/</td><td>sample_logs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/samples/</td><td>samples/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sfo_customer_survey/</td><td>sfo_customer_survey/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sms_spam_collection/</td><td>sms_spam_collection/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/songs/</td><td>songs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/structured-streaming/</td><td>structured-streaming/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/timeseries/</td><td>timeseries/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/tpch/</td><td>tpch/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/warmup/</td><td>warmup/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/weather/</td><td>weather/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wiki/</td><td>wiki/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wikipedia-datasets/</td><td>wikipedia-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wine-quality/</td><td>wine-quality/</td><td>0</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The **`display()`** command has the following capabilities and limitations:\n* Preview of results limited to 1000 records\n* Provides button to download results data as CSV\n* Allows rendering plots"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d99b71b0-48ae-4dda-9370-a5ba9271ae36"}}},{"cell_type":"markdown","source":["## Downloading Notebooks\n\nThere are a number of options for downloading either individual notebooks or collections of notebooks.\n\nHere, you'll go through the process to download this notebook as well as a collection of all the notebooks in this course.\n\n### Download a Notebook\n\nSteps:\n* Click the **File** option to the right of the cluster selection at the top of the notebook\n* From the menu that appears, hover over **Export** and then select **Source File**\n\nThe notebook will download to your personal laptop. It will be named with the current notebook name and have the file extension for the default language. You can open this notebook with any file editor and see the raw contents of Databricks notebooks.\n\nThese source files can be uploaded into any Databricks workspace.\n\n### Download a Collection of Notebooks\n\n**NOTE**: The following instructions assume you have imported these materials using **Repos**.\n\nSteps:\n* Click the  ![](https://files.training.databricks.com/images/repos-icon.png) **Repos** on the left sidebar\n  * This should give you a preview of the parent directories for this notebook\n* On the left side of the directory preview around the middle of the screen, there should be a left arrow. Click this to move up in your file hierarchy.\n* You should see a directory called **Data Engineering with Databricks**. Click the the down arrow/chevron to bring up a menu\n* From the menu, hover over **Export** and select **DBC Archive**\n\nThe DBC(Databricks Cloud) file that is downloaded contains a zipped collection of the directories and notebooks in this course. Users should not attempt to edit these DBC files locally, but they can be safely uploaded into any Databricks workspace to move or share notebook contents.\n\n**NOTE**: When downloading a collection of DBCs, result previews and plots will also be exported. When downloading source notebooks, only code will be saved."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"579b232e-e444-4113-b514-6aa1843bb5cd"}}},{"cell_type":"markdown","source":["## Learning More\n\nWe like to encourage you to explore the documentation to learn more about the various features of the Databricks platform and notebooks.\n* <a href=\"https://docs.databricks.com/user-guide/index.html#user-guide\" target=\"_blank\">User Guide</a>\n* <a href=\"https://docs.databricks.com/user-guide/getting-started.html\" target=\"_blank\">Getting Started with Databricks</a>\n* <a href=\"https://docs.databricks.com/user-guide/notebooks/index.html\" target=\"_blank\">User Guide / Notebooks</a>\n* <a href=\"https://docs.databricks.com/notebooks/notebooks-manage.html#notebook-external-formats\" target=\"_blank\">Importing notebooks - Supported Formats</a>\n* <a href=\"https://docs.databricks.com/repos/index.html\" target=\"_blank\">Repos</a>\n* <a href=\"https://docs.databricks.com/administration-guide/index.html#administration-guide\" target=\"_blank\">Administration Guide</a>\n* <a href=\"https://docs.databricks.com/user-guide/clusters/index.html\" target=\"_blank\">Cluster Configuration</a>\n* <a href=\"https://docs.databricks.com/api/latest/index.html#rest-api-2-0\" target=\"_blank\">REST API</a>\n* <a href=\"https://docs.databricks.com/release-notes/index.html#release-notes\" target=\"_blank\">Release Notes</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48ce9c52-532e-434a-a759-42559dab1a59"}}},{"cell_type":"markdown","source":["## One more note! \n\nAt the end of each lesson you will see the following command, **`DA.cleanup()`**.\n\nThis method drops lesson-specific databases and working directories in an attempt to keep your workspace clean and maintain the immutability of each lesson.\n\nRun the following cell to delete the tables and files associated with this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb8ad05d-2292-4dc4-a2da-bbcfc9ef61dd"}}},{"cell_type":"code","source":["DA.cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c6146d6-0d1c-49d9-b6d1-0c9a61c8c991"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9299cc67-6e5c-4a98-844c-209206c4e796"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DE 1.2 - Notebook Basics","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2841292000076311}},"nbformat":4,"nbformat_minor":0}
