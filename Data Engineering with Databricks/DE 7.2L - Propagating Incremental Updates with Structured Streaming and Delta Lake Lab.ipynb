{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"520a6bbc-b2d0-4362-8c46-35d72e2dbb85"}}},{"cell_type":"markdown","source":["# Propagating Incremental Updates with Structured Streaming and Delta Lake\n\n## Learning Objectives\nBy the end of this lab, you should be able to:\n* Apply your knowledge of structured streaming and Auto Loader to implement a simple multi-hop architecture"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"711814f5-a0f0-4a9c-bbb2-36015478db78"}}},{"cell_type":"markdown","source":["## Setup\nRun the following script to setup necessary variables and clear out past runs of this notebook. Note that re-executing this cell will allow you to start the lab over."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5e05c91-ece7-4e5f-a096-cab4ed432a1b"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup-7.2L"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8bf5b6b0-7ce3-4dd6-9c3a-7ed8da53b2c1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Ingest data\n\nThis lab uses a collection of customer-related CSV data from DBFS found in */databricks-datasets/retail-org/customers/*.\n\nRead this data using Auto Loader using its schema inference (use **`customers_checkpoint_path`** to store the schema info). Stream the raw data to a Delta table called **`bronze`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50aa768b-d7d0-452b-ae40-789585e35133"}}},{"cell_type":"code","source":["customers_checkpoint_path = f\"{DA.paths.checkpoints}/customers\"\n\nquery = (spark.readStream\n              .format(\"cloudFiles\")\n              .option(\"cloudFiles.format\", \"csv\")\n              .option(\"cloudFiles.schemaLocation\", customers_checkpoint_path)\n              .load(\"/databricks-datasets/retail-org/customers/\")\n              .writeStream\n              .format(\"delta\")\n              .option(\"checkpointLocation\", customers_checkpoint_path)\n              .outputMode(\"append\")\n              .table(\"bronze\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7de9cda6-79f6-4f85-9038-e61b7ebec0d9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["DA.block_until_stream_is_ready(query)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a9c604b-705f-43c8-bf5c-8baa6a72869a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the cell below to check your work."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"184c53d1-eee8-496b-9c75-b6449caaabf5"}}},{"cell_type":"code","source":["assert spark.table(\"bronze\"), \"Table named `bronze` does not exist\"\nassert spark.sql(f\"SHOW TABLES\").filter(f\"tableName == 'bronze'\").first()[\"isTemporary\"] == False, \"Table is temporary\"\nassert spark.table(\"bronze\").dtypes ==  [('customer_id', 'string'), ('tax_id', 'string'), ('tax_code', 'string'), ('customer_name', 'string'), ('state', 'string'), ('city', 'string'), ('postcode', 'string'), ('street', 'string'), ('number', 'string'), ('unit', 'string'), ('region', 'string'), ('district', 'string'), ('lon', 'string'), ('lat', 'string'), ('ship_to_address', 'string'), ('valid_from', 'string'), ('valid_to', 'string'), ('units_purchased', 'string'), ('loyalty_segment', 'string'), ('_rescued_data', 'string')], \"Incorrect Schema\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d91d399-a937-42fa-a31f-6b9ebb619ccd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's create a streaming temporary view into the bronze table, so that we can perform transforms using SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa47c759-4de4-4989-9324-85c3bd4ca055"}}},{"cell_type":"code","source":["(spark\n  .readStream\n  .table(\"bronze\")\n  .createOrReplaceTempView(\"bronze_temp\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c5ce76e-c8dc-429f-85d1-f660c94b07c5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Clean and enhance data\n\nUsing CTAS syntax, define a new streaming view called **`bronze_enhanced_temp`** that does the following:\n* Skips records with a null **`postcode`** (set to zero)\n* Inserts a column called **`receipt_time`** containing a current timestamp\n* Inserts a column called **`source_file`** containing the input filename"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db00d306-abbd-42f7-b9be-5458bf2fe169"}}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TEMPORARY VIEW bronze_enhanced_temp AS\nSELECT\n  *, current_timestamp() receipt_time, input_file_name() source_file\n  FROM bronze_temp\n  WHERE postcode > 0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d603ef85-bcf4-4945-8390-6aea5031feb0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the cell below to check your work."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8d226f4-2ad9-4709-8fc4-ab7308289f0a"}}},{"cell_type":"code","source":["assert spark.table(\"bronze_enhanced_temp\"), \"Table named `bronze_enhanced_temp` does not exist\"\nassert spark.sql(f\"SHOW TABLES\").filter(f\"tableName == 'bronze_enhanced_temp'\").first()[\"isTemporary\"] == True, \"Table is not temporary\"\nassert spark.table(\"bronze_enhanced_temp\").dtypes ==  [('customer_id', 'string'), ('tax_id', 'string'), ('tax_code', 'string'), ('customer_name', 'string'), ('state', 'string'), ('city', 'string'), ('postcode', 'string'), ('street', 'string'), ('number', 'string'), ('unit', 'string'), ('region', 'string'), ('district', 'string'), ('lon', 'string'), ('lat', 'string'), ('ship_to_address', 'string'), ('valid_from', 'string'), ('valid_to', 'string'), ('units_purchased', 'string'), ('loyalty_segment', 'string'), ('_rescued_data', 'string'), ('receipt_time', 'timestamp'), ('source_file', 'string')], \"Incorrect Schema\"\nassert spark.table(\"bronze_enhanced_temp\").isStreaming, \"Not a streaming table\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7dd54d6-3748-40ba-9a13-797fd8102f05"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Silver table\n\nStream the data from **`bronze_enhanced_temp`** to a table called **`silver`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1814d5b0-2f79-4713-84a2-3829ec45e7d3"}}},{"cell_type":"code","source":["silver_checkpoint_path = f\"{DA.paths.checkpoints}/silver\"\n\nquery = (spark.table(\"bronze_enhanced_temp\")\n              .writeStream\n              .format(\"delta\")\n              .option(\"checkpointLocation\", silver_checkpoint_path)\n              .outputMode(\"append\")\n              .table(\"silver\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"512cf17c-2788-4a6a-894e-23a7454c9b38"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["DA.block_until_stream_is_ready(query)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"def1e254-49bb-4193-8095-d4d8fc3fae94"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the cell below to check your work."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0c2b7c4-bf87-4a5a-abd6-fc91d7180a06"}}},{"cell_type":"code","source":["assert spark.table(\"silver\"), \"Table named `silver` does not exist\"\nassert spark.sql(f\"SHOW TABLES\").filter(f\"tableName == 'silver'\").first()[\"isTemporary\"] == False, \"Table is temporary\"\nassert spark.table(\"silver\").dtypes ==  [('customer_id', 'string'), ('tax_id', 'string'), ('tax_code', 'string'), ('customer_name', 'string'), ('state', 'string'), ('city', 'string'), ('postcode', 'string'), ('street', 'string'), ('number', 'string'), ('unit', 'string'), ('region', 'string'), ('district', 'string'), ('lon', 'string'), ('lat', 'string'), ('ship_to_address', 'string'), ('valid_from', 'string'), ('valid_to', 'string'), ('units_purchased', 'string'), ('loyalty_segment', 'string'), ('_rescued_data', 'string'), ('receipt_time', 'timestamp'), ('source_file', 'string')], \"Incorrect Schema\"\nassert spark.table(\"silver\").filter(\"postcode <= 0\").count() == 0, \"Null postcodes present\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68570780-0652-4eac-9984-a6de82acf890"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's create a streaming temporary view into the silver table, so that we can perform business-level using SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7684a8e-6a20-4309-9994-42b782d2d387"}}},{"cell_type":"code","source":["(spark\n  .readStream\n  .table(\"silver\")\n  .createOrReplaceTempView(\"silver_temp\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51a4e644-e7cf-4197-8a4c-ce1f918347b2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Gold tables\n\nUsing CTAS syntax, define a new streaming view called **`customer_count_temp`** that counts customers per state."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0cffe898-e49c-4b1b-a7e9-af6c24bdc73d"}}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TEMPORARY VIEW customer_count_temp AS\nSELECT state, count(customer_id) AS customer_count\nFROM silver_temp\nGROUP BY\nstate"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6193033-5766-422e-88c1-71600c2e37c4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the cell below to check your work."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86e5294f-ee44-464d-a825-316e30a75778"}}},{"cell_type":"code","source":["assert spark.table(\"customer_count_temp\"), \"Table named `customer_count_temp` does not exist\"\nassert spark.sql(f\"SHOW TABLES\").filter(f\"tableName == 'customer_count_temp'\").first()[\"isTemporary\"] == True, \"Table is not temporary\"\nassert spark.table(\"customer_count_temp\").dtypes ==  [('state', 'string'), ('customer_count', 'bigint')], \"Incorrect Schema\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e438ac14-b732-42b4-a3b5-69b328c2d5a5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Finally, stream the data from the **`customer_count_temp`** view to a Delta table called **`gold_customer_count_by_state`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06a5fbe6-dcea-46ff-bb0d-70a33f884c6b"}}},{"cell_type":"code","source":["customers_count_checkpoint_path = f\"{DA.paths.checkpoints}/customers_counts\"\n\nquery = (spark.table(\"customer_count_temp\")\n              .writeStream\n              .format(\"delta\")\n              .option(\"checkpointLocation\", customers_count_checkpoint_path)\n              .outputMode(\"complete\")\n              .table(\"gold_customer_count_by_state\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94e63b9f-9e52-47b5-bf29-7f4667f92ada"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["DA.block_until_stream_is_ready(query)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b439ac1-41cd-4b92-9daf-48b0b2712261"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the cell below to check your work."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c66e438-4c66-4b20-8700-b06ac0a2cd0e"}}},{"cell_type":"code","source":["assert spark.table(\"gold_customer_count_by_state\"), \"Table named `gold_customer_count_by_state` does not exist\"\nassert spark.sql(f\"show tables\").filter(f\"tableName == 'gold_customer_count_by_state'\").first()[\"isTemporary\"] == False, \"Table is temporary\"\nassert spark.table(\"gold_customer_count_by_state\").dtypes ==  [('state', 'string'), ('customer_count', 'bigint')], \"Incorrect Schema\"\nassert spark.table(\"gold_customer_count_by_state\").count() == 51, \"Incorrect number of rows\" "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b18371f4-3c23-46a8-a6e5-0e1ee082af16"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Query the results\n\nQuery the **`gold_customer_count_by_state`** table (this will not be a streaming query). Plot the results as a bar graph and also using the map plot."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67ab9016-3946-4aa1-9b5d-e2853c8969fa"}}},{"cell_type":"code","source":["%sql\nSELECT * FROM gold_customer_count_by_state"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea470800-def0-46e9-82bf-44ded1d99b0f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Wrapping Up\n\nRun the following cell to remove the database and all data associated with this lab."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8787ac8-4fd9-4745-aa77-bb47913d85a9"}}},{"cell_type":"code","source":["DA.cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6488806-728b-41e4-a9e9-260141db8911"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["By completing this lab, you should now feel comfortable:\n* Using PySpark to configure Auto Loader for incremental data ingestion\n* Using Spark SQL to aggregate streaming data\n* Streaming data to a Delta table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b91baf55-729b-4335-a697-bb9d92364be6"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b688b1b0-4866-4a83-b2d3-a74d494e5573"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DE 7.2L - Propagating Incremental Updates with Structured Streaming and Delta Lake Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2841292000077363}},"nbformat":4,"nbformat_minor":0}
