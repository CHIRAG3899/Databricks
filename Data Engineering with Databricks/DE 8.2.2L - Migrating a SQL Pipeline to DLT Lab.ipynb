{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b375adb-b645-4c1b-95e5-160ee1a98f5d"}}},{"cell_type":"markdown","source":["# Lab: Migrating a SQL Pipeline to Delta Live Tables\n\nThis notebook will be completed by you to implement a DLT pipeline using SQL. \n\nIt is **not intended** to be executed interactively, but rather to be deployed as a pipeline once you have completed your changes.\n\nTo aid in completion of this Notebook, please refer to the <a href=\"https://docs.databricks.com/data-engineering/delta-live-tables/delta-live-tables-language-ref.html#sql\" target=\"_blank\">DLT syntax documentation</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5acee60-d7a2-4c9f-87de-f21d55e97a76"}}},{"cell_type":"markdown","source":["## Declare Bronze Table\n\nDeclare a bronze table that ingests JSON data incrementally (using Auto Loader) from the simulated cloud source. The source location is already supplied as an argument; using this value is illustrated in the cell below.\n\nAs we did previously, include two additional columns:\n* **`receipt_time`** that records a timestamp as returned by **`current_timestamp()`** \n* **`source_file`** that is obtained by **`input_file_name()`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbe34fd1-604d-4783-b3c3-b6b1125798bf"}}},{"cell_type":"code","source":["%sql\nCREATE OR REFRESH STREAMING LIVE TABLE recordings_bronze\nAS SELECT current_timestamp() receipt_time, input_file_name() source_file, *\n  FROM cloud_files(\"${source}\", \"json\", map(\"cloudFiles.schemaHints\", \"time DOUBLE\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8282c969-3f23-40ad-9364-e509b681e301"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### PII File\n\nUsing a similar CTAS syntax, create a live **table** into the CSV data found at */mnt/training/healthcare/patient*.\n\nTo properly configure Auto Loader for this source, you will need to specify the following additional parameters:\n\n| option | value |\n| --- | --- |\n| **`header`** | **`true`** |\n| **`cloudFiles.inferColumnTypes`** | **`true`** |\n\n<img src=\"https://files.training.databricks.com/images/icon_note_24.png\"/> Auto Loader configurations for CSV can be found <a href=\"https://docs.databricks.com/spark/latest/structured-streaming/auto-loader-csv.html\" target=\"_blank\">here</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5dbb43a-85b6-42da-9639-c80b820fe03d"}}},{"cell_type":"code","source":["%sql\nCREATE OR REFRESH STREAMING LIVE TABLE pii\nAS SELECT *\n  FROM cloud_files(\"/mnt/training/healthcare/patient\", \"csv\", map(\"header\", \"true\", \"cloudFiles.inferColumnTypes\", \"true\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9eac3119-cb7f-4cf7-a7a8-253cc978a366"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Declare Silver Tables\n\nOur silver table, **`recordings_parsed`**, will consist of the following fields:\n\n| Field | Type |\n| --- | --- |\n| **`device_id`** | **`INTEGER`** |\n| **`mrn`** | **`LONG`** |\n| **`heartrate`** | **`DOUBLE`** |\n| **`time`** | **`TIMESTAMP`** (example provided below) |\n| **`name`** | **`STRING`** |\n\nThis query should also enrich the data through an inner join with the **`pii`** table on the common **`mrn`** field to obtain the name.\n\nImplement quality control by applying a constraint to drop records with an invalid **`heartrate`** (that is, not greater than zero)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64914b31-87b6-4ec5-ab90-c642e084aab8"}}},{"cell_type":"code","source":["%sql\nCREATE OR REFRESH STREAMING LIVE TABLE recordings_enriched\n  (CONSTRAINT positive_heartrate EXPECT (heartrate > 0) ON VIOLATION DROP ROW)\nAS SELECT \n  CAST(a.device_id AS INTEGER) device_id, \n  CAST(a.mrn AS LONG) mrn, \n  CAST(a.heartrate AS DOUBLE) heartrate, \n  CAST(from_unixtime(a.time, 'yyyy-MM-dd HH:mm:ss') AS TIMESTAMP) time,\n  b.name\n  FROM STREAM(live.recordings_bronze) a\n  INNER JOIN STREAM(live.pii) b\n  ON a.mrn = b.mrn"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1e484fa-5646-4929-a5dc-273b7ccd8f67"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Gold Table\n\nCreate a gold table, **`daily_patient_avg`**, that aggregates **`recordings_enriched`** by **`mrn`**, **`name`**, and **`date`** and delivers the following columns:\n\n| Column name | Value |\n| --- | --- |\n| **`mrn`** | **`mrn`** from source |\n| **`name`** | **`name`** from source |\n| **`avg_heartrate`** | Average **`heartrate`** from the grouping |\n| **`date`** | Date extracted from **`time`** |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d8d664a-e7c1-44e6-ba27-4441e5830b8e"}}},{"cell_type":"code","source":["%sql\nCREATE OR REFRESH STREAMING LIVE TABLE daily_patient_avg\n  COMMENT \"Daily mean heartrates by patient\"\n  AS SELECT mrn, name, MEAN(heartrate) avg_heartrate, DATE(time) `date`\n    FROM STREAM(live.recordings_enriched)\n    GROUP BY mrn, name, DATE(time)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7b1b362-a262-4953-9330-e0f71794a3ce"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44685f97-cac4-479f-be6e-ddf4056efc6a"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DE 8.2.2L - Migrating a SQL Pipeline to DLT Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2841292000077002}},"nbformat":4,"nbformat_minor":0}
